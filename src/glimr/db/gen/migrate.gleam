//// Migration Generator
////
//// Compares current schema definitions against a stored snapshot
//// to detect changes and automatically generate migration SQL.
////
//// The workflow is:
//// 1. Load the previous schema snapshot from JSON
//// 2. Scan current schema files in src/data/{conn_name}/models/
//// 3. Compute the diff (new tables, dropped tables, column changes)
//// 4. Generate driver-specific SQL (PostgreSQL or SQLite)
//// 5. Write migration file to src/data/{conn_name}/_migrations/
//// 6. Update the snapshot for next run
////
//// Supports column renames via the `rename_from` modifier, which
//// is automatically cleaned up after migration generation.
////
//// Run with: `gleam run -m glimr/db/gen/migrate`

import gleam/int
import gleam/io
import gleam/list
import gleam/option.{type Option, None, Some}
import gleam/string
import glimr/console/console
import glimr/db/gen/migrate/cleanup
import glimr/db/gen/migrate/snapshot
import glimr/db/gen/migrate/sql.{Postgres, Sqlite}
import glimr/db/gen/migrate/validation
import glimr/db/gen/schema_parser.{type Table}
import shellout
import simplifile

// ------------------------------------------------------------- Public Functions

/// Run migration generation for a named connection.
/// Uses the folder structure:
/// - src/data/{name}/models/
/// - src/data/{name}/_migrations/
/// - src/data/{name}/._schema_snapshot.json
///
pub fn run(
  name: String,
  driver_type: String,
  model_filter: Option(List(String)),
) {
  io.println("")
  io.println(console.warning("Glimr Migration Generator"))
  io.println("  Connection: " <> name)
  io.println("  Driver: " <> driver_type)

  let is_filtered = option.is_some(model_filter)
  case model_filter {
    Some(models) -> io.println("  Models: " <> string.join(models, ", "))
    None -> Nil
  }

  // Folder structure: src/data/{name}/...
  let base_path = "src/data/" <> name
  let models_path = base_path <> "/models"
  let snapshot_path = base_path <> "/._schema_snapshot.json"
  let migrations_path = base_path <> "/_migrations"

  // Convert driver type string to sql.Driver
  let sql_driver = case driver_type {
    "postgres" -> Postgres
    "sqlite" -> Sqlite
    _ -> {
      io.println("  Error: Unknown driver type '" <> driver_type <> "'")
      io.println("  Valid types: postgres, sqlite")
      panic as "Invalid driver type"
    }
  }

  do_run(
    models_path,
    snapshot_path,
    migrations_path,
    sql_driver,
    name,
    model_filter,
    is_filtered,
  )
}

// ------------------------------------------------------------- Private Functions

/// Internal implementation that handles the actual migration
/// generation logic.
///
fn do_run(
  models_path: String,
  snapshot_path: String,
  migrations_path: String,
  drv: sql.Driver,
  driver_name: String,
  model_filter: Option(List(String)),
  is_filtered: Bool,
) {
  // Load existing snapshot
  let old_snapshot = snapshot.load(snapshot_path)

  // Ensure migrations directory exists
  let _ = simplifile.create_directory_all(migrations_path)

  // Scan current schemas (filtered if specified)
  case scan_schemas(models_path, model_filter) {
    Ok(tables) -> {
      // Validate no duplicate column names
      validation.validate_no_duplicate_columns(tables)

      io.println(
        "  Found " <> int.to_string(list.length(tables)) <> " table(s)",
      )

      // Build new snapshot (only for scanned tables)
      let new_snapshot = snapshot.build(tables)

      // Compute diff (skip drop detection when filtering by model)
      let diff =
        sql.compute_diff(old_snapshot, new_snapshot, tables, is_filtered)

      case diff.changes {
        [] -> {
          io.println("")
          io.println("  No changes detected.")
        }
        changes -> {
          io.println("")
          io.println(
            "  Detected "
            <> int.to_string(list.length(changes))
            <> " change(s):",
          )
          list.each(changes, fn(change) {
            io.println("    - " <> sql.describe_change(change))
          })

          // Generate migration SQL for the configured driver only
          let timestamp = get_timestamp()
          let filename = timestamp <> "_migration.sql"
          let migration_sql = sql.generate_sql(diff, drv)

          // Write migration file
          let migration_path = migrations_path <> "/" <> filename

          let content =
            "-- Generated by glimr/db/gen/migrate ("
            <> driver_name
            <> ")\n\n"
            <> migration_sql
            <> "\n"

          case simplifile.write(migration_path, content) {
            Ok(_) -> {
              io.println("")
              io.println("  Generated: " <> migration_path)

              // Update snapshot (merge when filtered, replace when not)
              let final_snapshot = case is_filtered {
                True -> snapshot.merge(old_snapshot, new_snapshot)
                False -> new_snapshot
              }
              case snapshot.save(snapshot_path, final_snapshot) {
                Ok(_) -> io.println("  Updated: " <> snapshot_path)
                Error(_) ->
                  io.println("  Warning: Could not update snapshot file")
              }

              // Clean up rename_from modifiers from schema files
              cleanup.clean_rename_from_modifiers(models_path)
            }
            Error(_) -> io.println("  Error: Could not write migration file")
          }
        }
      }
    }
    Error(err) -> {
      io.println("  Error: " <> err)
    }
  }

  io.println("")
  io.println(console.success("  Done!"))
}

/// Scan model directories and parse their schema files. Applies
/// the optional filter to limit which models are scanned.
///
fn scan_schemas(
  models_path: String,
  model_filter: Option(List(String)),
) -> Result(List(Table), String) {
  case simplifile.read_directory(models_path) {
    Ok(entries) -> {
      let model_dirs =
        list.filter(entries, fn(entry) {
          case simplifile.is_directory(models_path <> "/" <> entry) {
            Ok(True) -> {
              // Apply filter if specified
              case model_filter {
                None -> True
                Some(allowed) -> list.contains(allowed, entry)
              }
            }
            _ -> False
          }
        })

      let tables =
        list.filter_map(model_dirs, fn(model_name) {
          let schema_path =
            models_path
            <> "/"
            <> model_name
            <> "/"
            <> model_name
            <> "_schema.gleam"
          case simplifile.read(schema_path) {
            Ok(content) -> {
              case schema_parser.parse(content) {
                Ok(table) -> Ok(table)
                Error(_) -> Error(Nil)
              }
            }
            Error(_) -> Error(Nil)
          }
        })

      Ok(tables)
    }
    Error(_) -> Error("Could not read " <> models_path)
  }
}

/// Get current timestamp in YYYYMMDDHHMMSS format for migration
/// filenames.
///
fn get_timestamp() -> String {
  case shellout.command("date", ["+%Y%m%d%H%M%S"], ".", []) {
    Ok(output) -> string.trim(output)
    Error(_) -> "00000000000000"
  }
}
